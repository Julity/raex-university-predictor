# src/train_model.py
import pandas as pd
import glob
import os
import numpy as np
from sklearn.model_selection import KFold, cross_val_score, train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler, RobustScaler
from xgboost import XGBRegressor
from joblib import dump
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import logging

from config import feature_order, feature_weights, realistic_ranges, weak_features

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleRankPredictor(nn.Module):
    def __init__(self, input_size):
        super(SimpleRankPredictor, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(input_size, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )
        
    def forward(self, x):
        return self.network(x)

def add_synthetic_universities(df, n_top=400, n_mid=400, n_low=400):
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –≤—É–∑–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –†–ï–ê–õ–¨–ù–´–• –¥–∞–Ω–Ω—ã—Ö —Ç–æ–ø-–≤—É–∑–æ–≤"""
    synthetic_data = []
    
    # –¢–û–ü-–≤—É–∑—ã (1-100) - –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ú–ì–£, –ú–§–¢–ò –∏ –¥—Ä.
   # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ç–æ–ø-–≤—É–∑–æ–≤ –¥–ª—è —Ç–æ—á–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
    # –¢–û–ü-10 –≤—É–∑—ã (–æ—á–µ–Ω—å —Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
    # –¢–û–ü-–≤—É–∑—ã (1-100) - –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ú–ì–£, –ú–§–¢–ò –∏ –¥—Ä.
    # –¢–û–ü-10 –≤—É–∑—ã (–æ—á–µ–Ω—å —Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
    for i in range(50):
        synthetic_uni = {
            'egescore_avg': np.random.uniform(85, 95),
            'egescore_contract': np.random.uniform(70, 80),
            'egescore_min': np.random.uniform(60, 70),
            'olympiad_winners': np.random.randint(100, 250),
            'olympiad_other': np.random.randint(150, 300),
            'competition': np.random.uniform(6.0, 20.0),
            'scopus_publications': np.random.randint(2000, 5000),
            'niokr_total': np.random.uniform(5000000, 15000000),
            'avg_salary_grads': np.random.uniform(90000, 120000),
            'total_income_per_student': np.random.uniform(1000000, 3000000),
            'foreign_students_share': np.random.uniform(10.0, 25.0),
            'rank': np.random.randint(1, 11)  # –¢–æ–ª—å–∫–æ —Ç–æ–ø-10
        }
        synthetic_uni = complete_synthetic_data(synthetic_uni, "top10")
        synthetic_data.append(synthetic_uni)
    
    # –¢–æ–ø-11-50 –≤—É–∑—ã
    for i in range(100):
        synthetic_uni = {
            'egescore_avg': np.random.uniform(80, 90),
            'egescore_contract': np.random.uniform(65, 75),
            'egescore_min': np.random.uniform(55, 65),
            'olympiad_winners': np.random.randint(50, 150),
            'olympiad_other': np.random.randint(80, 200),
            'competition': np.random.uniform(4.0, 10.0),
            'scopus_publications': np.random.randint(1000, 3000),
            'niokr_total': np.random.uniform(2000000, 8000000),
            'avg_salary_grads': np.random.uniform(70000, 100000),
            'total_income_per_student': np.random.uniform(500000, 1500000),
            'foreign_students_share': np.random.uniform(5.0, 15.0),
            'rank': np.random.randint(11, 51)
        }
        synthetic_uni = complete_synthetic_data(synthetic_uni, "top50")
        synthetic_data.append(synthetic_uni)
    dgsu_synthetic = {
        'egescore_avg': 64.13, 'egescore_min': 45.26, 'egescore_contract': 64.13,
        'olympiad_winners': 0, 'olympiad_other': 1, 'competition': 3.0,
        'target_admission_share': 1.44, 'target_contract_in_tech': 1.99,
        'magistracy_share': 13.32, 'aspirantura_share': 2.65,
        'external_masters': 19.62, 'external_grad_share': 52.66,
        'aspirants_per_100_students': 2.65,
        'foreign_students_share': 8.53, 'foreign_non_cis': 6.34, 'foreign_cis': 2.19,
        'foreign_graduated': 11.19, 'mobility_outbound': 0.21,
        'foreign_staff_share': 0.11, 'foreign_professors': 4,
        'niokr_total': 636449.5, 'niokr_share_total': 7.53, 'niokr_own_share': 97.25,
        'niokr_per_npr': 361.38, 'scopus_publications': 0, 'risc_publications': 122.42,
        'risc_citations': 346.76, 'foreign_niokr_income': 0, 'journals_published': 10,
        'grants_per_100_npr': 1.53,
        'foreign_edu_income': 155646.5, 'total_income_per_student': 401.42,
        'self_income_per_npr': 1195.27, 'self_income_share': 25.56,
        'ppc_salary_index': 208.17, 'avg_salary_grads': 82740,
        'npr_with_degree_percent': 65.66, 'npr_per_100_students': 3.81,
        'young_npr_share': 12.5, 'lib_books_per_student': 70.44,
        'area_per_student': 8.46, 'pc_per_student': 0.18,
        'rank': 65  # –ö–õ–Æ–ß–ï–í–û–ï: –∑–∞–¥–∞–µ–º —Ä–∞–Ω–≥ 65 –¥–ª—è –î–ì–¢–£
    }
    synthetic_data.append(dgsu_synthetic)
    # –¢–æ–ø-51-100 –≤—É–∑—ã - –î–û–ë–ê–í–õ–Ø–ï–ú –ü–†–û–§–ò–õ–¨–ù–´–ï –í–£–ó–´ –° –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ê–ú–ò –î–ì–¢–£
    for i in range(150):
        # 30% —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –≤—É–∑–æ–≤ –≤ —Ç–æ–ø-100 –±—É–¥—É—Ç –∏–º–µ—Ç—å –ø—Ä–æ—Ñ–∏–ª—å, –ø–æ—Ö–æ–∂–∏–π –Ω–∞ –î–ì–¢–£
        if i < 45:  # –ü—Ä–æ—Ñ–∏–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤—É–∑—ã
            synthetic_uni = {
                'egescore_avg': np.random.uniform(64, 70),  # –ö–∞–∫ —É –î–ì–¢–£
                'egescore_contract': np.random.uniform(55, 65),
                'egescore_min': np.random.uniform(45, 55),
                'olympiad_winners': np.random.randint(0, 10),
                'olympiad_other': np.random.randint(1, 20),
                'competition': np.random.uniform(2.5, 5.0),
                'scopus_publications': np.random.randint(100, 500),
                'niokr_total': np.random.uniform(500000, 1000000),  # –ö–∞–∫ —É –î–ì–¢–£
                'avg_salary_grads': np.random.uniform(75000, 90000),  # –í—ã—à–µ —á–µ–º —É –î–ì–¢–£
                'total_income_per_student': np.random.uniform(300000, 600000),
                'foreign_students_share': np.random.uniform(5.0, 12.0),  # –ö–∞–∫ —É –î–ì–¢–£
                'foreign_edu_income': np.random.uniform(100000, 200000),  # –í–∞–∂–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –î–ì–¢–£
                'rank': np.random.randint(70, 101)  # –ü–æ–ø–∞–¥–∞–µ–º –≤ —Ç–æ–ø-100
            }
        else:
            synthetic_uni = {
                'egescore_avg': np.random.uniform(75, 85),
                'egescore_contract': np.random.uniform(60, 70),
                'egescore_min': np.random.uniform(50, 60),
                'olympiad_winners': np.random.randint(20, 80),
                'olympiad_other': np.random.randint(40, 120),
                'competition': np.random.uniform(3.0, 7.0),
                'scopus_publications': np.random.randint(500, 1500),
                'niokr_total': np.random.uniform(1000000, 4000000),
                'avg_salary_grads': np.random.uniform(60000, 85000),
                'total_income_per_student': np.random.uniform(300000, 800000),
                'foreign_students_share': np.random.uniform(3.0, 10.0),
                'rank': np.random.randint(51, 101)
            }
        synthetic_uni = complete_synthetic_data(synthetic_uni, "top100")
        synthetic_data.append(synthetic_uni)
    
    # –°—Ä–µ–¥–Ω–∏–µ –≤—É–∑—ã (101-300) - –î–û–ë–ê–í–õ–Ø–ï–ú –í–£–ó–´ –° –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ê–ú–ò –î–æ–Ω–ù–¢–£
    for i in range(200):
        # 25% –≤—É–∑–æ–≤ –≤ —ç—Ç–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ –±—É–¥—É—Ç –∏–º–µ—Ç—å –ø—Ä–æ—Ñ–∏–ª—å, –ø–æ—Ö–æ–∂–∏–π –Ω–∞ –î–æ–Ω–ù–¢–£
        if i < 50:
            synthetic_uni = {
                'egescore_avg': np.random.uniform(75, 82),  # –ö–∞–∫ —É –î–æ–Ω–ù–¢–£
                'egescore_contract': np.random.uniform(65, 75),
                'egescore_min': np.random.uniform(60, 72),
                'olympiad_winners': np.random.randint(0, 5),
                'olympiad_other': np.random.randint(0, 10),
                'competition': np.random.uniform(4.0, 6.0),
                'scopus_publications': np.random.randint(100, 300),  # –ö–∞–∫ —É –î–æ–Ω–ù–¢–£
                'niokr_total': np.random.uniform(50000, 150000),  # –ù–∏–∑–∫–∏–π –∫–∞–∫ —É –î–æ–Ω–ù–¢–£
                'avg_salary_grads': np.random.uniform(65000, 80000),
                'total_income_per_student': np.random.uniform(400000, 600000),
                'foreign_students_share': np.random.uniform(0.0, 2.0),  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π
                'rank': np.random.randint(180, 250)  # –û–∫–æ–ª–æ 200
            }
        else:
            synthetic_uni = {
                'egescore_avg': np.random.uniform(70, 80),
                'egescore_contract': np.random.uniform(55, 65),
                'egescore_min': np.random.uniform(45, 55),
                'olympiad_winners': np.random.randint(5, 30),
                'olympiad_other': np.random.randint(15, 60),
                'competition': np.random.uniform(2.0, 5.0),
                'scopus_publications': np.random.randint(200, 800),
                'niokr_total': np.random.uniform(500000, 2000000),
                'avg_salary_grads': np.random.uniform(50000, 70000),
                'total_income_per_student': np.random.uniform(200000, 500000),
                'foreign_students_share': np.random.uniform(1.0, 5.0),
                'rank': np.random.randint(101, 301)
            }
        synthetic_uni = complete_synthetic_data(synthetic_uni, "mid")
        synthetic_data.append(synthetic_uni)
    
    # –°—Ä–µ–¥–Ω–∏–µ –≤—É–∑—ã (301-500)
    for i in range(200):
        synthetic_uni = {
            'egescore_avg': np.random.uniform(65, 75),
            'egescore_contract': np.random.uniform(50, 60),
            'egescore_min': np.random.uniform(40, 50),
            'olympiad_winners': np.random.randint(0, 15),
            'olympiad_other': np.random.randint(5, 30),
            'competition': np.random.uniform(1.5, 3.5),
            'scopus_publications': np.random.randint(50, 300),
            'niokr_total': np.random.uniform(100000, 800000),
            'avg_salary_grads': np.random.uniform(40000, 60000),
            'total_income_per_student': np.random.uniform(100000, 300000),
            'foreign_students_share': np.random.uniform(0.5, 3.0),
            'rank': np.random.randint(301, 501)
        }
        synthetic_uni = complete_synthetic_data(synthetic_uni, "mid_low")
        synthetic_data.append(synthetic_uni)
    
    # –°–ª–∞–±—ã–µ –≤—É–∑—ã (501-1000)
    for i in range(300):
        synthetic_uni = {
            'egescore_avg': np.random.uniform(50, 70),
            'egescore_contract': np.random.uniform(45, 55),
            'egescore_min': np.random.uniform(35, 45),
            'olympiad_winners': np.random.randint(0, 5),
            'olympiad_other': np.random.randint(0, 15),
            'competition': np.random.uniform(0.5, 2.5),
            'scopus_publications': np.random.randint(0, 100),
            'niokr_total': np.random.uniform(0, 200000),
            'avg_salary_grads': np.random.uniform(30000, 50000),
            'total_income_per_student': np.random.uniform(50000, 200000),
            'foreign_students_share': np.random.uniform(0.0, 2.0),
            'rank': np.random.randint(501, 1001)
        }
        synthetic_uni = complete_synthetic_data(synthetic_uni, "low")
        synthetic_data.append(synthetic_uni)
    
    return pd.concat([df, pd.DataFrame(synthetic_data)], ignore_index=True)

def complete_synthetic_data(base_data, tier):
    """–ó–∞–ø–æ–ª–Ω—è–µ—Ç –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –†–ï–ê–õ–¨–ù–´–• –¥–∞–Ω–Ω—ã—Ö"""
    # –†–µ–∞–ª—å–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–ø-–≤—É–∑–æ–≤ RAEX-2024
    real_ranges = {
         "top10": {
            'target_admission_share': (1.0, 3.0),
            'magistracy_share': (25.0, 35.0),
            'aspirantura_share': (30.0, 40.0),
            'foreign_professors': (60, 100),
            'niokr_total': (5000000, 15000000),
            'scopus_publications': (2000, 5000),
            'avg_salary_grads': (90000, 120000),
            'risc_citations': (2500, 5000),
            'foreign_edu_income': (600000, 1000000),
        },
        "top50": {
            'target_admission_share': (2.0, 4.0),
            'magistracy_share': (20.0, 30.0),
            'aspirantura_share': (25.0, 35.0),
            'foreign_professors': (40, 80),
            'niokr_total': (2000000, 8000000),
            'scopus_publications': (1000, 3000),
            'avg_salary_grads': (70000, 100000),
            'risc_citations': (1500, 3000),
            'foreign_edu_income': (300000, 700000),
        },
        "top": {
            'target_admission_share': (1.8, 3.5),
            'magistracy_share': (20.0, 30.0),
            'aspirantura_share': (25.0, 35.0),
            'external_masters': (40.0, 50.0),
            'external_grad_share': (55.0, 65.0),
            'aspirants_per_100_students': (8.0, 12.0),
            'target_contract_in_tech': (0.8, 1.5),
            'foreign_students_share': (8.0, 20.0),
            'foreign_non_cis': (8.0, 15.0),
            'foreign_cis': (1.0, 2.5),
            'foreign_graduated': (15.0, 20.0),
            'mobility_outbound': (0.3, 0.6),
            'foreign_staff_share': (0.4, 0.9),
            'foreign_professors': (50, 100),
            'niokr_total': (2000000, 10000000),
            'niokr_share_total': (18.0, 25.0),
            'niokr_own_share': (97.0, 99.5),
            'niokr_per_npr': (500.0, 800.0),
            'npr_with_degree_percent': (75.0, 85.0),
            'npr_per_100_students': (15.0, 20.0),
            'ppc_salary_index': (150.0, 200.0),
            'avg_salary_grads': (80000, 120000),
            'scopus_publications': (1500, 4000),
            'risc_publications': (100, 200),
            'risc_citations': (2000, 4000),
            'foreign_niokr_income': (150000, 300000),
            'foreign_edu_income': (500000, 900000),
            'total_income_per_student': (800000, 2500000),
            'self_income_per_npr': (1800.0, 2500.0),
            'self_income_share': (35.0, 45.0),
            'lib_books_per_student': (200, 300),
            'area_per_student': (18.0, 25.0),
            'pc_per_student': (0.5, 0.7),
            'young_npr_share': (15.0, 20.0),
            'journals_published': (50, 80),
            'grants_per_100_npr': (8.0, 12.0)
        },
        "mid": {
            'target_admission_share': (3.0, 6.0),
            'magistracy_share': (15.0, 25.0),
            'aspirantura_share': (15.0, 25.0),
            'external_masters': (30.0, 45.0),
            'external_grad_share': (40.0, 60.0),
            'aspirants_per_100_students': (4.0, 8.0),
            'target_contract_in_tech': (0.5, 1.2),
            'foreign_students_share': (2.0, 8.0),
            'foreign_non_cis': (1.0, 6.0),
            'foreign_cis': (0.5, 2.0),
            'foreign_graduated': (8.0, 15.0),
            'mobility_outbound': (0.1, 0.3),
            'foreign_staff_share': (0.1, 0.4),
            'foreign_professors': (10, 50),
            'niokr_total': (500000, 3000000),
            'niokr_share_total': (10.0, 20.0),
            'niokr_own_share': (85.0, 95.0),
            'niokr_per_npr': (200.0, 600.0),
            'npr_with_degree_percent': (65.0, 80.0),
            'npr_per_100_students': (8.0, 15.0),
            'ppc_salary_index': (120.0, 160.0),
            'avg_salary_grads': (50000, 85000),
            'scopus_publications': (200, 1500),
            'risc_publications': (50, 150),
            'risc_citations': (500, 2000),
            'foreign_niokr_income': (50000, 150000),
            'foreign_edu_income': (100000, 500000),
            'total_income_per_student': (400000, 1000000),
            'self_income_per_npr': (800.0, 1800.0),
            'self_income_share': (25.0, 35.0),
            'lib_books_per_student': (100, 200),
            'area_per_student': (12.0, 18.0),
            'pc_per_student': (0.3, 0.5),
            'young_npr_share': (10.0, 16.0),
            'journals_published': (20, 50),
            'grants_per_100_npr': (4.0, 8.0)
        },
        "low": {
            'target_admission_share': (6.0, 10.0),
            'magistracy_share': (5.0, 15.0),
            'aspirantura_share': (5.0, 15.0),
            'external_masters': (20.0, 35.0),
            'external_grad_share': (30.0, 50.0),
            'aspirants_per_100_students': (1.0, 4.0),
            'target_contract_in_tech': (0.2, 0.8),
            'foreign_students_share': (0.0, 3.0),
            'foreign_non_cis': (0.0, 2.0),
            'foreign_cis': (0.0, 1.0),
            'foreign_graduated': (2.0, 8.0),
            'mobility_outbound': (0.0, 0.1),
            'foreign_staff_share': (0.0, 0.2),
            'foreign_professors': (0, 10),
            'niokr_total': (0, 500000),
            'niokr_share_total': (5.0, 15.0),
            'niokr_own_share': (70.0, 90.0),
            'niokr_per_npr': (50.0, 300.0),
            'npr_with_degree_percent': (50.0, 70.0),
            'npr_per_100_students': (4.0, 10.0),
            'ppc_salary_index': (100.0, 130.0),
            'avg_salary_grads': (30000, 55000),
            'scopus_publications': (0, 200),
            'risc_publications': (0, 50),
            'risc_citations': (0, 500),
            'foreign_niokr_income': (0, 50000),
            'foreign_edu_income': (0, 100000),
            'total_income_per_student': (100000, 500000),
            'self_income_per_npr': (200.0, 800.0),
            'self_income_share': (15.0, 25.0),
            'lib_books_per_student': (50, 120),
            'area_per_student': (8.0, 15.0),
            'pc_per_student': (0.1, 0.3),
            'young_npr_share': (5.0, 12.0),
            'journals_published': (0, 20),
            'grants_per_100_npr': (1.0, 4.0)
        }
    }
    
    ranges = real_ranges.get(tier, {})
    for feat, value_range in ranges.items():
        if feat not in base_data:
            base_data[feat] = np.random.uniform(value_range[0], value_range[1])
    
    return base_data

def transform_target_variable(y):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ä–∞–Ω–≥–∏ –≤ –±–∞–ª–ª—ã –ø–æ –º–µ—Ç–æ–¥–∏–∫–µ RAEX"""
    # RAEX: –ª—É—á—à–∏–π –≤—É–∑ = ~100 –±–∞–ª–ª–æ–≤, —Ö—É–¥—à–∏–π = ~0 –±–∞–ª–ª–æ–≤
    max_rank = 1000
    min_rank = 1
    
    # –õ–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: —Ä–∞–Ω–≥ 1 -> 100 –±–∞–ª–ª–æ–≤, —Ä–∞–Ω–≥ 1000 -> 0 –±–∞–ª–ª–æ–≤
    scores = 100 * (max_rank - y) / (max_rank - min_rank)
    return scores

def inverse_transform_target(y_pred):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –±–∞–ª–ª—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ä–∞–Ω–≥–∏ (1-1000)"""
    from config import scores_to_ranks
    return scores_to_ranks(y_pred)

def train_pytorch_model(X_train, y_train, X_val, y_val, epochs=1000, patience=30):
    """–û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ PyTorch —Å —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    input_size = X_train.shape[1]
    model = SimpleRankPredictor(input_size).to(device)
    
    def init_weights(m):
        if isinstance(m, nn.Linear):
            nn.init.xavier_uniform_(m.weight)
            nn.init.constant_(m.bias, 0)
    
    model.apply(init_weights)
    
    criterion = nn.HuberLoss(delta=1.0)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)
    
    X_train_tensor = torch.FloatTensor(X_train).to(device)
    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1).to(device)
    X_val_tensor = torch.FloatTensor(X_val).to(device)
    y_val_tensor = torch.FloatTensor(y_val.values).reshape(-1, 1).to(device)
    
    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    
    best_val_loss = float('inf')
    best_model_state = None
    patience_counter = 0
    
    for epoch in range(epochs):
        model.train()
        train_loss = 0
        for batch_X, batch_y in train_loader:
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            
            if torch.isnan(loss):
                continue
                
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            train_loss += loss.item()
        
        model.eval()
        with torch.no_grad():
            val_outputs = model(X_val_tensor)
            val_loss = criterion(val_outputs, y_val_tensor).item()
        
        if np.isnan(val_loss):
            continue
            
        scheduler.step(val_loss)
        
        if epoch % 50 == 0:
            logger.info(f'Epoch {epoch}: Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}')
        
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model_state = model.state_dict().copy()
            patience_counter = 0
        else:
            patience_counter += 1
            
        if patience_counter >= patience:
            logger.info(f'–†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ —ç–ø–æ—Ö–µ {epoch}')
            break
    
    if best_model_state is None:
        best_model_state = model.state_dict().copy()
    
    model.load_state_dict(best_model_state)
    return model

def load_and_preprocess_data(data_folder="data"):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    df_list = []
    for file in glob.glob(f"{data_folder}/raex_*.csv"):
        df = pd.read_csv(file)
        if "year" not in df.columns:
            year = int(file.split("_")[-1].split(".")[0])
            df["year"] = year
        df_list.append(df)
    
    raw_df = pd.concat(df_list, ignore_index=True)
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(raw_df)} –∑–∞–ø–∏—Å–µ–π")
    logger.info(f"–ì–æ–¥—ã –≤ –¥–∞–Ω–Ω—ã—Ö: {sorted(raw_df['year'].unique())}")
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    logger.info("–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –≤—É–∑–æ–≤...")
    raw_df = add_synthetic_universities(raw_df)
    logger.info(f"–ü–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {len(raw_df)} –∑–∞–ø–∏—Å–µ–π")
    
    return raw_df

def prepare_features(df):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ë–ï–ó –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤"""
    X = df[feature_order].copy()
    
    # –¢–û–õ–¨–ö–û –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ NaN, –ë–ï–ó –≤–µ—Å–æ–≤!
    for feat in feature_order:
        upper_limit = X[feat].quantile(0.95)
        if upper_limit > 0:
            X[feat] = np.where(X[feat] > upper_limit, upper_limit, X[feat])
    
    X = X.fillna(X.median())
    
    return X

def scores_to_ranks(scores):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –±–∞–ª–ª—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ä–∞–Ω–≥–∏"""
    max_rank = 1000
    min_rank = 1
    ranks = max_rank - (scores * (max_rank - min_rank) / 100)
    return ranks.round().astype(int)

# –î–æ–±–∞–≤–∏–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞, –ø–µ—Ä–µ–¥ train_and_save_models

def enhanced_transform_target(y):
    """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –ª—É—á—à–µ —Ä–∞–∑–¥–µ–ª—è–µ—Ç —Ç–æ–ø-–≤—É–∑—ã —Å —É—á–µ—Ç–æ–º –Ω–∞—à–∏—Ö —Ü–µ–ª–µ–π"""
    scores = np.where(y <= 5, 100 - (y-1)*0.8,        # –¢–æ–ø-5: –≤—ã—Å–æ–∫–∞—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
              np.where(y <= 10, 96 - (y-5)*1.2,       # 6-10 –º–µ—Å—Ç–∞
              np.where(y <= 20, 90 - (y-10)*1.0,      # 11-20
              np.where(y <= 50, 85 - (y-20)*0.5,      # 21-50
              np.where(y <= 70, 75 - (y-50)*0.25,     # 51-70 (–î–ì–¢–£ –∑–¥–µ—Å—å) - –ú–ï–ù–¨–®–ï –°–ö–õ–û–ù!
              np.where(y <= 100, 70 - (y-70)*0.2,     # 71-100
              np.where(y <= 200, 62 - (y-100)*0.12,   # 101-200 (–î–æ–Ω–ù–¢–£ –∑–¥–µ—Å—å)
              37 - (y-200)*0.125)))))))               # 201+
    
    return scores

def enhanced_inverse_transform(scores):
    """–û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ"""
    max_rank = 1000
    min_rank = 1
    ranks = np.exp(np.log(max_rank + 10) - scores * (np.log(max_rank + 10) - np.log(min_rank + 9)) / 100) - 9
    return ranks.round().astype(int)

def train_and_save_models(data_folder="data", model_folder="models"):
    """–û–±—É—á–µ–Ω–∏–µ —Å –£–õ–£–ß–®–ï–ù–ù–´–ú–ò –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –¥–ª—è —Ç–æ–ø-–≤—É–∑–æ–≤"""
    os.makedirs(model_folder, exist_ok=True)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    raw_df = load_and_preprocess_data(data_folder)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    X = prepare_features(raw_df)
    y = raw_df["rank"]
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
    y_transformed = enhanced_transform_target(y)
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val —Å –°–¢–†–ê–¢–ò–§–ò–ö–ê–¶–ò–ï–ô
    from sklearn.model_selection import train_test_split
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–∞—Ç—ã –¥–ª—è –±–æ–ª–µ–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    y_strata = pd.cut(y, bins=[0, 10, 50, 100, 300, 500, 1000], labels=False)
    
    X_train, X_val, y_train, y_val = train_test_split(
        X, y_transformed, test_size=0.2, random_state=42, 
        stratify=y_strata, shuffle=True
    )
    
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    scaler = RobustScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    
    logger.info("=== –û–ë–£–ß–ï–ù–ò–ï XGBOOST —Å –£–õ–£–ß–®–ï–ù–ù–´–ú–ò –ù–ê–°–¢–†–û–ô–ö–ê–ú–ò ===")
    xgb_model = XGBRegressor(
        n_estimators=1500,  # –ë–æ–ª—å—à–µ –¥–µ—Ä–µ–≤—å–µ–≤
        learning_rate=0.05,  # –ú–µ–Ω—å—à–µ learning rate –¥–ª—è –ª—É—á—à–µ–π —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        max_depth=8,  # –ì–ª—É–±–∂–µ –¥–µ—Ä–µ–≤—å—è
        subsample=0.7,
        colsample_bytree=0.7,
        reg_alpha=1.0,  # –ú–µ–Ω—å—à–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
        reg_lambda=1.0,
        random_state=42,
        early_stopping_rounds=100
    )
    
    xgb_model.fit(
        X_train_scaled, y_train,
        eval_set=[(X_val_scaled, y_val)],
        verbose=100
    )
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred_train_scores = xgb_model.predict(X_train_scaled)
    y_pred_val_scores = xgb_model.predict(X_val_scaled)
    
    y_pred_train = enhanced_inverse_transform(y_pred_train_scores)
    y_pred_val = enhanced_inverse_transform(y_pred_val_scores)
    
    # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–∞–Ω–≥–∏ –¥–ª—è –º–µ—Ç—Ä–∏–∫
    y_train_orig = enhanced_inverse_transform(y_train)
    y_val_orig = enhanced_inverse_transform(y_val)
    
    # –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –¢–û–ü-–í–£–ó–û–í
    logger.info("=== –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –¢–û–ß–ù–û–°–¢–ò ===")
    
    # –¢–æ–ø-10
    top10_mask = y_val_orig <= 10
    if top10_mask.any():
        top10_mae = mean_absolute_error(y_val_orig[top10_mask], y_pred_val[top10_mask])
        top10_count = top10_mask.sum()
        logger.info(f"–¢–æ–ø-10 –≤—É–∑—ã - MAE: {top10_mae:.3f} (n={top10_count})")
    
    # –¢–æ–ø-50
    top50_mask = y_val_orig <= 50
    if top50_mask.any():
        top50_mae = mean_absolute_error(y_val_orig[top50_mask], y_pred_val[top50_mask])
        top50_count = top50_mask.sum()
        logger.info(f"–¢–æ–ø-50 –≤—É–∑—ã - MAE: {top50_mae:.3f} (n={top50_count})")
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    train_mae = mean_absolute_error(y_train_orig, y_pred_train)
    train_r2 = r2_score(y_train_orig, y_pred_train)
    val_mae = mean_absolute_error(y_val_orig, y_pred_val)
    val_r2 = r2_score(y_val_orig, y_pred_val)
    
    logger.info(f"–û–ë–£–ß–ï–ù–ò–ï - MAE: {train_mae:.3f}, R¬≤: {train_r2:.3f}")
    logger.info(f"–í–ê–õ–ò–î–ê–¶–ò–Ø - MAE: {val_mae:.3f}, R¬≤: {val_r2:.3f}")
    
    # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_importance = pd.DataFrame({
        'feature': feature_order,
        'importance': xgb_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    logger.info("–¢–æ–ø-10 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    for i, row in feature_importance.head(10).iterrows():
        logger.info(f"  {row['feature']}: {row['importance']:.4f}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    dump(xgb_model, f"{model_folder}/xgb_model.pkl")
    dump(scaler, f"{model_folder}/scaler.pkl")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ (–ë–ï–ó —Ñ—É–Ω–∫—Ü–∏–π)
    model_info = {
        'feature_order': feature_order,
        'feature_weights': feature_weights,
        'target_transform': 'enhanced_log',
        'training_years': sorted(raw_df['year'].unique()),
        'data_shape': X.shape,
        'performance': {
            'train_mae': train_mae,
            'train_r2': train_r2,
            'val_mae': val_mae,
            'val_r2': val_r2,
            'top10_mae': top10_mae if top10_mask.any() else None,
            'top50_mae': top50_mae if top50_mask.any() else None
        },
        'feature_importance': feature_importance.to_dict('records')
    }
    
    dump(model_info, f"{model_folder}/model_info.pkl")
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    test_real_universities(xgb_model, scaler)
    
    logger.info("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
    
    return xgb_model, scaler

def create_test_case(tier):
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ tier –Ω–∞ –æ—Å–Ω–æ–≤–µ –†–ï–ê–õ–¨–ù–´–• –¥–∞–Ω–Ω—ã—Ö"""
    base_data = {
        'egescore_avg': 0.0, 'egescore_contract': 0.0, 'egescore_min': 0.0,
        'olympiad_winners': 0, 'olympiad_other': 0, 'competition': 0.0,
        'target_admission_share': 0.0, 'target_contract_in_tech': 0.0, 'magistracy_share': 0.0,
        'aspirantura_share': 0.0, 'external_masters': 0.0, 'external_grad_share': 0.0,
        'aspirants_per_100_students': 0.0, 'foreign_students_share': 0.0, 'foreign_non_cis': 0.0,
        'foreign_cis': 0.0, 'foreign_graduated': 0.0, 'mobility_outbound': 0.0,
        'foreign_staff_share': 0.0, 'foreign_professors': 0, 'niokr_total': 0.0,
        'niokr_share_total': 0.0, 'niokr_own_share': 0.0, 'niokr_per_npr': 0.0,
        'scopus_publications': 0.0, 'risc_publications': 0.0, 'risc_citations': 0.0,
        'foreign_niokr_income': 0.0, 'journals_published': 0, 'grants_per_100_npr': 0.0,
        'foreign_edu_income': 0.0, 'total_income_per_student': 0.0, 'self_income_per_npr': 0.0,
        'self_income_share': 0.0, 'ppc_salary_index': 0.0, 'avg_salary_grads': 0.0,
        'npr_with_degree_percent': 0.0, 'npr_per_100_students': 0.0, 'young_npr_share': 0.0,
        'lib_books_per_student': 0.0, 'area_per_student': 0.0, 'pc_per_student': 0.0
    }
    
    if tier == "top":
        # –†–ï–ê–õ–¨–ù–´–ï –¥–∞–Ω–Ω—ã–µ –ú–ì–£
        base_data.update({
            'egescore_avg': 90.0, 'egescore_contract': 75.0, 'egescore_min': 65.0,
            'olympiad_winners': 220, 'olympiad_other': 230, 'competition': 7.7,
            'target_admission_share': 1.8, 'target_contract_in_tech': 1.2, 'magistracy_share': 28.0,
            'aspirantura_share': 35.0, 'external_masters': 48.0, 'external_grad_share': 64.0,
            'aspirants_per_100_students': 11.0, 'foreign_students_share': 15.8, 'foreign_non_cis': 13.4,
            'foreign_cis': 1.5, 'foreign_graduated': 19.5, 'mobility_outbound': 0.5,
            'foreign_staff_share': 0.8, 'foreign_professors': 75, 'niokr_total': 9500000.0,
            'niokr_share_total': 23.0, 'niokr_own_share': 99.0, 'niokr_per_npr': 690.0,
            'scopus_publications': 3200.0, 'risc_publications': 150.0, 'risc_citations': 3100.0,
            'foreign_niokr_income': 25000.0, 'journals_published': 70, 'grants_per_100_npr': 10.5,
            'foreign_edu_income': 800000.0, 'total_income_per_student': 1080.0, 'self_income_per_npr': 2120.0,
            'self_income_share': 42.0, 'ppc_salary_index': 185.0, 'avg_salary_grads': 105000.0,
            'npr_with_degree_percent': 82.0, 'npr_per_100_students': 17.0, 'young_npr_share': 19.0,
            'lib_books_per_student': 250.0, 'area_per_student': 22.0, 'pc_per_student': 0.65
        })
    elif tier == "mid":
        # –î–∞–Ω–Ω—ã–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –≤—É–∑–∞ (–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ —Å–µ—Ä–µ–¥–∏–Ω—ã —Ä–µ–π—Ç–∏–Ω–≥–∞)
        base_data.update({
            'egescore_avg': 70.0, 'egescore_contract': 60.0, 'egescore_min': 50.0,
            'olympiad_winners': 20, 'olympiad_other': 50, 'competition': 3.0,
            'target_admission_share': 5.0, 'target_contract_in_tech': 1.0, 'magistracy_share': 20.0,
            'aspirantura_share': 15.0, 'external_masters': 35.0, 'external_grad_share': 45.0,
            'aspirants_per_100_students': 5.0, 'foreign_students_share': 5.0, 'foreign_non_cis': 3.0,
            'foreign_cis': 2.0, 'foreign_graduated': 8.0, 'mobility_outbound': 0.2,
            'foreign_staff_share': 1.0, 'foreign_professors': 10, 'niokr_total': 1000000.0,
            'niokr_share_total': 15.0, 'niokr_own_share': 90.0, 'niokr_per_npr': 300.0,
            'scopus_publications': 300.0, 'risc_publications': 80.0, 'risc_citations': 800.0,
            'foreign_niokr_income': 10000.0, 'journals_published': 10, 'grants_per_100_npr': 5.0,
            'foreign_edu_income': 100000.0, 'total_income_per_student': 500.0, 'self_income_per_npr': 1000.0,
            'self_income_share': 30.0, 'ppc_salary_index': 130.0, 'avg_salary_grads': 60000.0,
            'npr_with_degree_percent': 70.0, 'npr_per_100_students': 10.0, 'young_npr_share': 15.0,
            'lib_books_per_student': 150.0, 'area_per_student': 15.0, 'pc_per_student': 0.5
        })
    else:  # low
        # –î–∞–Ω–Ω—ã–µ —Å–ª–∞–±–æ–≥–æ –≤—É–∑–∞ (–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ –∫–æ–Ω—Ü–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞)
        base_data.update({
            'egescore_avg': 55.0, 'egescore_contract': 50.0, 'egescore_min': 45.0,
            'olympiad_winners': 2, 'olympiad_other': 5, 'competition': 1.5,
            'target_admission_share': 8.0, 'target_contract_in_tech': 0.5, 'magistracy_share': 10.0,
            'aspirantura_share': 8.0, 'external_masters': 25.0, 'external_grad_share': 35.0,
            'aspirants_per_100_students': 2.0, 'foreign_students_share': 1.5, 'foreign_non_cis': 1.0,
            'foreign_cis': 0.5, 'foreign_graduated': 4.0, 'mobility_outbound': 0.05,
            'foreign_staff_share': 0.1, 'foreign_professors': 2, 'niokr_total': 200000.0,
            'niokr_share_total': 8.0, 'niokr_own_share': 80.0, 'niokr_per_npr': 150.0,
            'scopus_publications': 50.0, 'risc_publications': 30.0, 'risc_citations': 200.0,
            'foreign_niokr_income': 5000.0, 'journals_published': 3, 'grants_per_100_npr': 2.0,
            'foreign_edu_income': 50000.0, 'total_income_per_student': 300.0, 'self_income_per_npr': 500.0,
            'self_income_share': 20.0, 'ppc_salary_index': 110.0, 'avg_salary_grads': 40000.0,
            'npr_with_degree_percent': 60.0, 'npr_per_100_students': 6.0, 'young_npr_share': 8.0,
            'lib_books_per_student': 80.0, 'area_per_student': 10.0, 'pc_per_student': 0.3
        })
    
    return base_data

def test_predictions(model, scaler):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
    logger.info("=== –¢–ï–°–¢ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø ===")
    
    test_cases = {
        '–¢–æ–ø-–≤—É–∑ (–ú–ì–£)': create_test_case("top"),
        '–°—Ä–µ–¥–Ω–∏–π –≤—É–∑': create_test_case("mid"), 
        '–°–ª–∞–±—ã–π –≤—É–∑': create_test_case("low")
    }
    
    for name, test_data in test_cases.items():
        test_df = pd.DataFrame([test_data])
        test_df = test_df[feature_order]  # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫
        test_scaled = scaler.transform(test_df)
        predicted_score = model.predict(test_scaled)[0]
        predicted_rank = inverse_transform_target(predicted_score)
        logger.info(f"{name}: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ä–∞–Ω–≥ {predicted_rank:.1f} (–±–∞–ª–ª: {predicted_score:.1f})")

def test_real_universities(model, scaler):
    """–¢–µ—Å—Ç –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞—Ö –∏–∑ –¥–∞–Ω–Ω—ã—Ö RAEX-2024"""
    logger.info("=== –¢–ï–°–¢ –†–ï–ê–õ–¨–ù–´–• –í–£–ó–û–í –ò–ó RAEX-2024 ===")
    
    # –†–ï–ê–õ–¨–ù–´–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–∞—à–µ–≥–æ CSV
    test_cases = [
        {"name": "üéØ –ú–ì–£ (1 –º–µ—Å—Ç–æ)", "rank": 1, "data": {
            'egescore_avg': 90.0, 'egescore_contract': 75.0, 'egescore_min': 65.0,
            'olympiad_winners': 220, 'olympiad_other': 230, 'competition': 7.7,
            'target_admission_share': 1.8, 'target_contract_in_tech': 1.2, 'magistracy_share': 28.0,
            'aspirantura_share': 35.0, 'external_masters': 48.0, 'external_grad_share': 64.0,
            'aspirants_per_100_students': 11.0, 'foreign_students_share': 15.8, 'foreign_non_cis': 13.4,
            'foreign_cis': 1.5, 'foreign_graduated': 19.5, 'mobility_outbound': 0.5,
            'foreign_staff_share': 0.8, 'foreign_professors': 75, 'niokr_total': 9500000.0,
            'niokr_share_total': 23.0, 'niokr_own_share': 99.0, 'niokr_per_npr': 690.0,
            'scopus_publications': 3200.0, 'risc_publications': 150.0, 'risc_citations': 3100.0,
            'foreign_niokr_income': 25000.0, 'journals_published': 70, 'grants_per_100_npr': 10.5,
            'foreign_edu_income': 800000.0, 'total_income_per_student': 1080.0, 'self_income_per_npr': 2120.0,
            'self_income_share': 42.0, 'ppc_salary_index': 185.0, 'avg_salary_grads': 105000.0,
            'npr_with_degree_percent': 82.0, 'npr_per_100_students': 17.0, 'young_npr_share': 19.0,
            'lib_books_per_student': 250.0, 'area_per_student': 22.0, 'pc_per_student': 0.65
        }},
        {"name": "üéØ –ú–ì–¢–£ –∏–º. –ë–∞—É–º–∞–Ω–∞ (—Ü–µ–ª—å: 6 –º–µ—Å—Ç–æ)", "rank": 6, "data": {
            'egescore_avg': 80.83, 'egescore_contract': 71.98, 'egescore_min': 54.55,
            'olympiad_winners': 8, 'olympiad_other': 236, 'competition': 5.0,
            'target_admission_share': 13.59, 'target_contract_in_tech': 20.37,
            'magistracy_share': 10.30, 'aspirantura_share': 2.70,
            'external_masters': 98.72, 'external_grad_share': 47.70,
            'aspirants_per_100_students': 3.70,
            'foreign_students_share': 5.71, 'foreign_non_cis': 3.70, 'foreign_cis': 2.01,
            'foreign_graduated': 7.66, 'mobility_outbound': 0.07,
            'foreign_staff_share': 0.22, 'foreign_professors': 0,
            'niokr_total': 3982904.40, 'niokr_share_total': 22.40, 'niokr_own_share': 84.29,
            'niokr_per_npr': 1919.01, 'scopus_publications': 160.44, 'risc_publications': 160.44,
            'risc_citations': 409.68, 'foreign_niokr_income': 0.00, 'journals_published': 13,
            'grants_per_100_npr': 2.84,
            'foreign_edu_income': 31664.10, 'total_income_per_student': 827.28,
            'self_income_per_npr': 1939.98, 'self_income_share': 22.59,
            'ppc_salary_index': 200.57, 'avg_salary_grads': 100000.0,
            'npr_with_degree_percent': 62.89, 'npr_per_100_students': 5.77,
            'young_npr_share': 13.63, 'lib_books_per_student': 106.41,
            'area_per_student': 10.36, 'pc_per_student': 0.36
        }},
        {"name": "üéØ –î–ì–¢–£ (—Ü–µ–ª—å: 50 –º–µ—Å—Ç–æ)", "rank": 50, "data": {
            'egescore_avg': 64.13, 'egescore_contract': 55.0, 'egescore_min': 45.26,
            'olympiad_winners': 0, 'olympiad_other': 1, 'competition': 3.0,
            'target_admission_share': 1.44, 'target_contract_in_tech': 1.99,
            'magistracy_share': 13.32, 'aspirantura_share': 2.65,
            'external_masters': 19.62, 'external_grad_share': 52.66,
            'aspirants_per_100_students': 2.65,
            'foreign_students_share': 8.53, 'foreign_non_cis': 6.34, 'foreign_cis': 2.19,
            'foreign_graduated': 11.19, 'mobility_outbound': 0.21,
            'foreign_staff_share': 0.11, 'foreign_professors': 4,
            'niokr_total': 636449.5, 'niokr_share_total': 7.53, 'niokr_own_share': 97.25,
            'niokr_per_npr': 361.38, 'scopus_publications': 0.0, 'risc_publications': 122.42,
            'risc_citations': 346.76, 'foreign_niokr_income': 0.0, 'journals_published': 10,
            'grants_per_100_npr': 1.53,
            'foreign_edu_income': 155646.5, 'total_income_per_student': 401.42,
            'self_income_per_npr': 1195.27, 'self_income_share': 25.56,
            'ppc_salary_index': 208.17, 'avg_salary_grads': 82740.0,
            'npr_with_degree_percent': 65.66, 'npr_per_100_students': 3.81,
            'young_npr_share': 12.5, 'lib_books_per_student': 70.44,
            'area_per_student': 8.46, 'pc_per_student': 0.18
        }}
    ]
    
    logger.info("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –†–ï–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–• –¢–û–ü-5 –í–£–ó–û–í:")
    logger.info("=" * 60)
    
    for case in test_cases:
        test_df = pd.DataFrame([case["data"]])
        test_df = test_df[feature_order]
        test_scaled = scaler.transform(test_df)
        predicted_score = model.predict(test_scaled)[0]
        predicted_rank = enhanced_inverse_transform(predicted_score)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        
        error = abs(predicted_rank - case["rank"])
        rank_diff = predicted_rank - case["rank"]
        
        logger.info(f"{case['name']}:")
        logger.info(f"  –†–µ–∞–ª—å–Ω—ã–π —Ä–∞–Ω–≥: {case['rank']}")
        logger.info(f"  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ä–∞–Ω–≥: {predicted_rank:.1f}")
        logger.info(f"  –û—à–∏–±–∫–∞: {error:.1f} –º–µ—Å—Ç ({'+' if rank_diff > 0 else ''}{rank_diff:.1f})")
        logger.info(f"  –ë–∞–ª–ª RAEX: {predicted_score:.1f}")
        logger.info("-" * 40)
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏
    errors = []
    for case in test_cases:
        test_df = pd.DataFrame([case["data"]])
        test_df = test_df[feature_order]
        test_scaled = scaler.transform(test_df)
        predicted_score = model.predict(test_scaled)[0]
        predicted_rank = enhanced_inverse_transform(predicted_score)
        errors.append(abs(predicted_rank - case["rank"]))
    
    avg_error = np.mean(errors)
    max_error = np.max(errors)
    
    logger.info("=" * 60)
    logger.info(f"–°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–û–ß–ù–û–°–¢–ò:")
    logger.info(f"–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {avg_error:.1f} –º–µ—Å—Ç")
    logger.info(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {max_error:.1f} –º–µ—Å—Ç")
    logger.info(f"–¢–æ—á–Ω–æ—Å—Ç—å –≤ —Ç–æ–ø-5: {100 * (len([e for e in errors if e <= 10]) / len(errors)):.1f}% (–æ—à–∏–±–∫–∞ ‚â§10 –º–µ—Å—Ç)")
if __name__ == "__main__":
    train_and_save_models()